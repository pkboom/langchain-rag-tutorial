{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/rag-chatbot.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/rag-chatbot.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install dspy-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-29 16:48:54--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham_es 100%[===================>]  73.28K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-03-29 16:48:54 (5.60 MB/s) - ‘data/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keunbae/code/langchain-rag-tutorial/.venv/lib/python3.11/site-packages/weaviate/warnings.py:158: DeprecationWarning: Dep016: You are using the Weaviate v3 client, which is deprecated.\n",
      "            Consider upgrading to the new and improved v4 client instead!\n",
      "            See here for usage: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import os\n",
    "\n",
    "# Connect to Weaviate client in embedded mode\n",
    "client = weaviate.Client(embedded_options=EmbeddedOptions(),\n",
    "                             additional_headers={\n",
    "                                \"X-OpenAI-Api-Key\": os.environ.get('OPENAI_API_KEY'),\n",
    "                             }\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Weaviate schema\n",
    "# DSPy assumes the collection has a text key 'content'\n",
    "schema = {\n",
    "   \"classes\": [\n",
    "       {\n",
    "           \"class\": \"MyExampleIndex\",\n",
    "           \"vectorizer\": \"text2vec-openai\",\n",
    "            \"moduleConfig\": {\"text2vec-openai\": {}},\n",
    "           \"properties\": [{\"name\": \"content\", \"dataType\": [\"text\"]}]\n",
    "       }      \n",
    "   ]\n",
    "}\n",
    "    \n",
    "# client.schema.create(schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Split document into single sentences\n",
    "chunks = []\n",
    "with open(\"./data/paul_graham_essay.txt\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    # split by sentence\n",
    "    sentences = re.split(r'[\\r\\n]+', text)\n",
    "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "    chunks.extend(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Populate vector database in batches\n",
    "client.batch.configure(batch_size=100)  # Configure batch\n",
    "\n",
    "with client.batch as batch:  # Initialize a batch process\n",
    "    for i, d in enumerate(chunks):  # Batch import data\n",
    "        properties = {\n",
    "            \"content\": d,\n",
    "        }\n",
    "        batch.add_data_object(\n",
    "            data_object=properties,\n",
    "            class_name=\"MyExampleIndex\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redacre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
